{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "horses_humans_transfer_learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devesh962/Binary-Classification/blob/master/horses_humans_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRONYixhx0dR",
        "colab_type": "code",
        "outputId": "af953ab4-4016-4a8e-a3eb-97cab12cd0fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11580
        }
      },
      "source": [
        "import os\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# pre_trained_model.summary()\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "pre_trained_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-30 13:45:42--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.188.128, 2404:6800:4008:c01::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.188.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  40.1MB/s    in 2.1s    \n",
            "\n",
            "2019-05-30 13:45:44 (40.1 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "last layer output shape:  (None, 7, 7, 768)\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_15 (Batc (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_15[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_13 (Batc (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_16 (Batc (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_13[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_16[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_14 (Batc (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_17 (Batc (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_18 (Batc (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_14[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_17[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_18[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_22 (Batc (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_22[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_20 (Batc (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_23 (Batc (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_20[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_23[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_19 (Batc (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_21 (Batc (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_24 (Batc (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_25 (Batc (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_19[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_21[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_24[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_25[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_27 (Batc (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_27[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_28 (Batc (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_28[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_26 (Batc (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_29 (Batc (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_v1_26[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_v1_29[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_34 (Batc (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_35 (Batc (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_31 (Batc (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_36 (Batc (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_31[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_32 (Batc (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_37 (Batc (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_30 (Batc (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_33 (Batc (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_38 (Batc (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_39 (Batc (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_30[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_39[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_44 (Batc (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_44[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_45 (Batc (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_45[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_41 (Batc (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_46 (Batc (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_41[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_46[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_42 (Batc (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_47 (Batc (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_42[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_47[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_40 (Batc (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_43 (Batc (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_48 (Batc (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_49 (Batc (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_40[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_43[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_48[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_49[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_54 (Batc (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_54[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_55 (Batc (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_55[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_51 (Batc (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_56 (Batc (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_51[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_56[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_52 (Batc (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_57 (Batc (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_52[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_57[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_50 (Batc (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_53 (Batc (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_58 (Batc (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_59 (Batc (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_50[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_53[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_58[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_59[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_64 (Batc (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_64[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_65 (Batc (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_65[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_61 (Batc (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_66 (Batc (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_61[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_66[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_62 (Batc (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_67 (Batc (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_62[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_67[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_60 (Batc (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_63 (Batc (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_68 (Batc (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_69 (Batc (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_60[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_63[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_68[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_69[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_72 (Batc (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_72[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_73 (Batc (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_73[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_70 (Batc (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_74 (Batc (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_70[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_74[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_71 (Batc (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_75 (Batc (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_71[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_75[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_80 (Batc (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_80[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_77 (Batc (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_81 (Batc (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_77[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_81[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_78 (Batc (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_79 (Batc (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_82 (Batc (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_83 (Batc (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_76 (Batc (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_78[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_79[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_82[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_83[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_84 (Batc (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_76[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_84[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_89 (Batc (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_89[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_86 (Batc (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_90 (Batc (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_86[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_90[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_87 (Batc (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_88 (Batc (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_91 (Batc (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_92 (Batc (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_85 (Batc (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_87[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_88[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_91[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_92[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_93 (Batc (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_85[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_93[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eU2WG_ejyaEB",
        "colab_type": "code",
        "outputId": "c114793a-f951-4a34-bf68-c964513159de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ue6mGlDByZRq",
        "colab_type": "code",
        "outputId": "51ee51cd-e063-41fb-d0f3-b895fa6ff38f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip \\\n",
        "    -O /tmp/horse-or-human.zip\n",
        "  \n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip \\\n",
        "    -O /tmp/validation-horse-or-human.zip\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-30 13:46:14--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.97.128, 2404:6800:4008:c01::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.97.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M  77.7MB/s    in 1.8s    \n",
            "\n",
            "2019-05-30 13:46:16 (77.7 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-05-30 13:46:19--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.125.128, 2404:6800:4008:c06::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.125.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  23.4MB/s    in 0.5s    \n",
            "\n",
            "2019-05-30 13:46:20 (23.4 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShKxuL-UyZOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip='/tmp/horse-or-human.zip'\n",
        "zip_ref=zipfile.ZipFile(local_zip,'r')\n",
        "zip_ref.extractall('/tmp/horse-or-human')\n",
        "local_zip='/tmp/validation-horse-or-human.zip'\n",
        "zip_ref=zipfile.ZipFile(local_zip,'r')\n",
        "zip_ref.extractall('/tmp/validation-horse-or-human')\n",
        "zip_ref.close()\n",
        "\n",
        "train_horse_dir=os.path.join('/tmp/horse-or-human/horses')\n",
        "train_human_dir=os.path.join('/tmp/horse-or-human/humans')\n",
        "test_horse_dir=os.path.join('/tmp/validation-horse-or-human/horses')\n",
        "test_human_dir=os.path.join('/tmp/validation-horse-or-human/humans')\n",
        "train_dir=os.path.join('/tmp/horse-or-human')\n",
        "validation_dir=os.path.join('/tmp/validation-horse-or-human')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EkWfDLVyZI2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "    \n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlz2RVdMyZEj",
        "colab_type": "code",
        "outputId": "4593399d-71b6-489c-dd72-e5c1ccd13726",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,  \n",
        "        target_size=(150, 150),  \n",
        "        batch_size=20,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')\n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZiDDiiXBRj7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.8% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "callbacks=myCallback()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-uM-WqHyY0J",
        "colab_type": "code",
        "outputId": "a54d5bfa-c362-465a-c3a5-b2ca8752f388",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2601
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=51,  # 2000 images = batch_size * steps\n",
        "      epochs=100,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=13,  # 1000 images = batch_size * steps\n",
        "    callbacks=[callbacks],\n",
        "      verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "13/13 [==============================] - 2s 126ms/step - loss: 0.1003 - acc: 0.9805\n",
            " - 15s - loss: 0.0188 - acc: 0.9942 - val_loss: 0.1003 - val_acc: 0.9805\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 2s 130ms/step - loss: 0.1736 - acc: 0.9727\n",
            " - 14s - loss: 0.0471 - acc: 0.9805 - val_loss: 0.1736 - val_acc: 0.9727\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 2s 127ms/step - loss: 0.0370 - acc: 0.9922\n",
            " - 14s - loss: 0.0353 - acc: 0.9922 - val_loss: 0.0370 - val_acc: 0.9922\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 2s 124ms/step - loss: 0.0526 - acc: 0.9883\n",
            " - 14s - loss: 0.0534 - acc: 0.9873 - val_loss: 0.0526 - val_acc: 0.9883\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 2s 128ms/step - loss: 0.0721 - acc: 0.9844\n",
            " - 14s - loss: 0.0136 - acc: 0.9981 - val_loss: 0.0721 - val_acc: 0.9844\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.0852 - acc: 0.9922\n",
            " - 14s - loss: 0.0264 - acc: 0.9912 - val_loss: 0.0852 - val_acc: 0.9922\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 2s 123ms/step - loss: 0.2027 - acc: 0.9648\n",
            " - 14s - loss: 0.0170 - acc: 0.9942 - val_loss: 0.2027 - val_acc: 0.9648\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 2s 125ms/step - loss: 0.2640 - acc: 0.9609\n",
            " - 14s - loss: 0.0344 - acc: 0.9912 - val_loss: 0.2640 - val_acc: 0.9609\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 2s 125ms/step - loss: 0.2614 - acc: 0.9609\n",
            " - 14s - loss: 0.0392 - acc: 0.9893 - val_loss: 0.2614 - val_acc: 0.9609\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 2s 124ms/step - loss: 0.0575 - acc: 0.9961\n",
            " - 14s - loss: 0.0118 - acc: 0.9951 - val_loss: 0.0575 - val_acc: 0.9961\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 2s 122ms/step - loss: 0.1664 - acc: 0.9648\n",
            " - 14s - loss: 0.0140 - acc: 0.9961 - val_loss: 0.1664 - val_acc: 0.9648\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 2s 123ms/step - loss: 0.1159 - acc: 0.9727\n",
            " - 14s - loss: 0.0094 - acc: 0.9971 - val_loss: 0.1159 - val_acc: 0.9727\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 2s 126ms/step - loss: 0.3188 - acc: 0.9648\n",
            " - 14s - loss: 0.0389 - acc: 0.9903 - val_loss: 0.3188 - val_acc: 0.9648\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 2s 122ms/step - loss: 0.2721 - acc: 0.9648\n",
            " - 14s - loss: 0.0137 - acc: 0.9961 - val_loss: 0.2721 - val_acc: 0.9648\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 2s 124ms/step - loss: 0.1893 - acc: 0.9648\n",
            " - 14s - loss: 0.0197 - acc: 0.9951 - val_loss: 0.1893 - val_acc: 0.9648\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 2s 122ms/step - loss: 0.3044 - acc: 0.9648\n",
            " - 14s - loss: 0.0049 - acc: 0.9981 - val_loss: 0.3044 - val_acc: 0.9648\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 2s 123ms/step - loss: 0.3812 - acc: 0.9648\n",
            " - 14s - loss: 0.0152 - acc: 0.9942 - val_loss: 0.3812 - val_acc: 0.9648\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 2s 124ms/step - loss: 0.3992 - acc: 0.9609\n",
            " - 14s - loss: 0.0253 - acc: 0.9883 - val_loss: 0.3992 - val_acc: 0.9609\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 2s 123ms/step - loss: 0.4591 - acc: 0.9609\n",
            " - 14s - loss: 0.0412 - acc: 0.9912 - val_loss: 0.4591 - val_acc: 0.9609\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 2s 121ms/step - loss: 0.3876 - acc: 0.9648\n",
            " - 14s - loss: 0.0336 - acc: 0.9922 - val_loss: 0.3876 - val_acc: 0.9648\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 0.2802 - acc: 0.9688\n",
            " - 14s - loss: 0.0224 - acc: 0.9951 - val_loss: 0.2802 - val_acc: 0.9688\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 2s 122ms/step - loss: 0.3959 - acc: 0.9648\n",
            " - 14s - loss: 0.0212 - acc: 0.9951 - val_loss: 0.3959 - val_acc: 0.9648\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 2s 121ms/step - loss: 0.3844 - acc: 0.9648\n",
            " - 14s - loss: 0.0250 - acc: 0.9942 - val_loss: 0.3844 - val_acc: 0.9648\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 0.5131 - acc: 0.9570\n",
            " - 14s - loss: 0.0332 - acc: 0.9942 - val_loss: 0.5131 - val_acc: 0.9570\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 2s 121ms/step - loss: 0.4867 - acc: 0.9570\n",
            " - 14s - loss: 0.0492 - acc: 0.9912 - val_loss: 0.4867 - val_acc: 0.9570\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.5405 - acc: 0.9570\n",
            " - 14s - loss: 0.0205 - acc: 0.9922 - val_loss: 0.5405 - val_acc: 0.9570\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 2s 124ms/step - loss: 0.4555 - acc: 0.9570\n",
            " - 14s - loss: 0.0136 - acc: 0.9951 - val_loss: 0.4555 - val_acc: 0.9570\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 2s 123ms/step - loss: 0.3478 - acc: 0.9570\n",
            " - 14s - loss: 0.0131 - acc: 0.9951 - val_loss: 0.3478 - val_acc: 0.9570\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 2s 125ms/step - loss: 0.4848 - acc: 0.9570\n",
            " - 14s - loss: 0.0236 - acc: 0.9942 - val_loss: 0.4848 - val_acc: 0.9570\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 0.7170 - acc: 0.9414\n",
            " - 14s - loss: 0.0071 - acc: 0.9971 - val_loss: 0.7170 - val_acc: 0.9414\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 0.3165 - acc: 0.9688\n",
            " - 13s - loss: 0.0091 - acc: 0.9951 - val_loss: 0.3165 - val_acc: 0.9688\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 2s 123ms/step - loss: 0.4733 - acc: 0.9609\n",
            " - 14s - loss: 0.0339 - acc: 0.9922 - val_loss: 0.4733 - val_acc: 0.9609\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 2s 123ms/step - loss: 0.7930 - acc: 0.9297\n",
            " - 14s - loss: 0.0190 - acc: 0.9951 - val_loss: 0.7930 - val_acc: 0.9297\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 2s 124ms/step - loss: 0.5002 - acc: 0.9609\n",
            " - 14s - loss: 0.0350 - acc: 0.9961 - val_loss: 0.5002 - val_acc: 0.9609\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 2s 123ms/step - loss: 0.4651 - acc: 0.9609\n",
            " - 14s - loss: 0.0160 - acc: 0.9922 - val_loss: 0.4651 - val_acc: 0.9609\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 2s 125ms/step - loss: 0.5305 - acc: 0.9609\n",
            " - 14s - loss: 0.0198 - acc: 0.9942 - val_loss: 0.5305 - val_acc: 0.9609\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 0.6156 - acc: 0.9453\n",
            " - 13s - loss: 0.0224 - acc: 0.9951 - val_loss: 0.6156 - val_acc: 0.9453\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 2s 123ms/step - loss: 0.2128 - acc: 0.9688\n",
            " - 14s - loss: 0.0563 - acc: 0.9883 - val_loss: 0.2128 - val_acc: 0.9688\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 2s 123ms/step - loss: 0.3960 - acc: 0.9609\n",
            " - 14s - loss: 0.0275 - acc: 0.9873 - val_loss: 0.3960 - val_acc: 0.9609\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 2s 124ms/step - loss: 0.2942 - acc: 0.9648\n",
            " - 14s - loss: 0.0106 - acc: 0.9981 - val_loss: 0.2942 - val_acc: 0.9648\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 2s 124ms/step - loss: 0.2521 - acc: 0.9648\n",
            " - 14s - loss: 0.0110 - acc: 0.9971 - val_loss: 0.2521 - val_acc: 0.9648\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 2s 124ms/step - loss: 0.3730 - acc: 0.9609\n",
            " - 14s - loss: 0.0222 - acc: 0.9912 - val_loss: 0.3730 - val_acc: 0.9609\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 2s 125ms/step - loss: 0.2919 - acc: 0.9648\n",
            " - 14s - loss: 0.0240 - acc: 0.9961 - val_loss: 0.2919 - val_acc: 0.9648\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 0.3159 - acc: 0.9609\n",
            " - 13s - loss: 0.0168 - acc: 0.9961 - val_loss: 0.3159 - val_acc: 0.9609\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 2s 121ms/step - loss: 0.2136 - acc: 0.9727\n",
            " - 14s - loss: 0.0146 - acc: 0.9951 - val_loss: 0.2136 - val_acc: 0.9727\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 0.2458 - acc: 0.9648\n",
            " - 14s - loss: 0.0202 - acc: 0.9912 - val_loss: 0.2458 - val_acc: 0.9648\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 2s 123ms/step - loss: 0.3090 - acc: 0.9609\n",
            " - 14s - loss: 0.0357 - acc: 0.9971 - val_loss: 0.3090 - val_acc: 0.9609\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 2s 122ms/step - loss: 0.5978 - acc: 0.9492\n",
            " - 13s - loss: 0.0083 - acc: 0.9971 - val_loss: 0.5978 - val_acc: 0.9492\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 0.3981 - acc: 0.9609\n",
            " - 14s - loss: 0.0141 - acc: 0.9961 - val_loss: 0.3981 - val_acc: 0.9609\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 0.4107 - acc: 0.9609\n",
            "\n",
            "Reached 99.8% accuracy so cancelling training!\n",
            " - 13s - loss: 0.0033 - acc: 0.9990 - val_loss: 0.4107 - val_acc: 0.9609\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7BJyEqM-_dR",
        "colab_type": "code",
        "outputId": "a5d410f3-4b81-42e5-8da5-f8df1c9c68da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzsnXd4VGX2xz+H3mtAFBAQUIhAEJCi\nIKIiwQ66KvaCuipr+VnWrmtvuJZ1XRsqqwuytrUgKCiLrg2EBASkLLIQmvSOkOT8/jhzk8lkyp3J\nJJkk7+d55pmZe9/73vfeufO95573vOcVVcXhcDgcVYNq5d0Ah8PhcJQdTvQdDoejCuFE3+FwOKoQ\nTvQdDoejCuFE3+FwOKoQTvQdDoejCuFEvwoiItVFZKeIHJzMsuWJiHQSkaTHH4vICSKyIuj7YhEZ\n5KdsAvt6RUTuSHR7h8MPNcq7AY7YiMjOoK/1gN+AvMD3q1T1rXjqU9U8oEGyy1YFVPWwZNQjIqOB\nC1T12KC6RyejbocjGk70KwCqWiC6AUtytKpOi1ReRGqoam5ZtM3hiIW7HlML596pBIjIgyLytohM\nEJEdwAUiMkBEvhORrSKyVkSeFZGagfI1RERFpH3g+5uB9Z+KyA4R+VZEOsRbNrB+uIgsEZFtIvKc\niPxHRC6J0G4/bbxKRJaJyBYReTZo2+oi8mcR2SQiy4HMKOfnThGZGLLseRF5KvB5tIgsChzPfwNW\neKS6ckTk2MDneiLy90DbFgC9Q8reJSLLA/UuEJHTAsu7A38BBgVcZxuDzu19Qdv/PnDsm0TkAxE5\n0M+5iec8e+0RkWkisllE1onIrUH7uTtwTraLyGwROSicK01EvvZ+58D5nBnYz2bgLhHpLCJfBvax\nMXDeGgdt3y5wjBsC658RkTqBNncNKnegiOwWkeaRjtcRA1V1rwr0AlYAJ4QsexDYB5yK3cjrAkcC\n/bCnuUOAJcCYQPkagALtA9/fBDYCfYCawNvAmwmUbQnsAE4PrPs/YD9wSYRj8dPGfwGNgfbAZu/Y\ngTHAAqAN0ByYaZdz2P0cAuwE6gfV/SvQJ/D91EAZAY4D9gA9AutOAFYE1ZUDHBv4/CQwA2gKtAMW\nhpQ9Gzgw8JucF2jDAYF1o4EZIe18E7gv8PnEQBt7AnWAvwJf+Dk3cZ7nxsB64HqgNtAI6BtYdzuQ\nDXQOHENPoBnQKfRcA197v3Pg2HKBq4Hq2PV4KHA8UCtwnfwHeDLoeH4KnM/6gfJHB9a9BDwUtJ+b\ngPfL+39YkV/l3gD3ivMHiyz6X8TY7mbgn4HP4YT8b0FlTwN+SqDsZcBXQesEWEsE0ffZxv5B698D\nbg58nom5ubx1J4UKUUjd3wHnBT4PBxZHKfsxcG3gczTRXxn8WwDXBJcNU+9PwMmBz7FE/w3g4aB1\njbB+nDaxzk2c5/lCYFaEcv/12huy3I/oL4/RhrO8/QKDgHVA9TDljgZ+ASTwPQsYmez/VVV6OfdO\n5WFV8BcR6SIinwQe17cD9wNpUbZfF/R5N9E7byOVPSi4HWr/0pxIlfhso699Af+L0l6AfwCjAp/P\nC3z32nGKiHwfcD1sxazsaOfK48BobRCRS0QkO+Ci2Ap08Vkv2PEV1Keq24EtQOugMr5+sxjnuS0m\n7uGIti4WoddjKxGZJCKrA214PaQNK9SCBoqgqv/BnhoGikg34GDgkwTb5MD59CsToeGKL2KWZSdV\nbQTcg1nepclazBIFQESEoiIVSknauBYTC49YIaWTgBNEpDXmfvpHoI11gXeARzDXSxPgM5/tWBep\nDSJyCPAC5uJoHqj356B6Y4WXrsFcRl59DTE30mof7Qol2nleBXSMsF2kdbsCbaoXtKxVSJnQ43sM\nizrrHmjDJSFtaCci1SO0YzxwAfZUMklVf4tQzuEDJ/qVl4bANmBXoCPsqjLY58dALxE5VURqYH7i\nFqXUxknADSLSOtCp98dohVV1HeaCeB1z7SwNrKqN+Zk3AHkicgrme/bbhjtEpInYOIYxQesaYMK3\nAbv/XYFZ+h7rgTbBHaohTAAuF5EeIlIbuyl9paoRn5yiEO08fwgcLCJjRKS2iDQSkb6Bda8AD4pI\nRzF6ikgz7Ga3DgsYqC4iVxJ0g4rShl3ANhFpi7mYPL4FNgEPi3WO1xWRo4PW/x1zB52H3QAcJcCJ\nfuXlJuBirGP1RazDtVRR1fXAOcBT2J+4IzAXs/CS3cYXgOnAfGAWZq3H4h+Yj77AtaOqW4Ebgfex\nztCzsJuXH+7FnjhWAJ8SJEiqOg94DvghUOYw4PugbT8HlgLrRSTYTeNtPwVzw7wf2P5g4Hyf7Qol\n4nlW1W3AUOBM7Ea0BBgcWP0E8AF2nrdjnap1Am67K4A7sE79TiHHFo57gb7YzedD4N2gNuQCpwBd\nMat/JfY7eOtXYL/zb6r6TZzH7gjB6xxxOJJO4HF9DXCWqn5V3u1xVFxEZDzWOXxfebelouMGZzmS\niohkYpEye7CQv/2YtetwJESgf+R0oHt5t6Uy4Nw7jmQzEFiO+bKHASNcx5sjUUTkEWyswMOqurK8\n21MZcO4dh8PhqEI4S9/hcDiqECnn009LS9P27duXdzMcDoejQvHjjz9uVNVoIdJACop++/btmT17\ndnk3w+FwOCoUIhJrVDrg3DsOh8NRpXCi73A4HFWImKIvIuNE5FcR+SnCegnkzV4mIvNEpFfQuotF\nZGngdXEyG+5wOByO+PFj6b9OlAkqsDS1nQOvK7Hh8QRydNyL5fHuC9wrIk1L0liHw+FwlIyYoq+q\nM7GcJJE4HRivxndAE7EZfoYBn6vqZlXdguUaiXbzcDgcDkcpkwyffmuK5s7OCSyLtLwYInJlYCq2\n2Rs2bEhCkxwOh8MRjpToyFXVl1S1j6r2adEiZpipw+FwOBIkGaK/mqITSbQJLIu03OFwOByhTJoE\nEyeW+m6SIfofAhcFonj6A9tUdS0wFThRRJoGOnBPDCxzOBwORzBLlsDll8Pzz0N+fqnuKuaIXBGZ\nABwLpIlIDhaRUxNAVf8GTMYmpV6GzdN5aWDdZhF5AJvgAuB+VY3WIexwOBxVj7174eyzoXZtmDAB\nqpWu1z2m6KvqqBjrFbg2wrpxwLjEmpaCbNkC//d/8Nhj0LJlebem/MnPh7vugkGDYPjw8m6No7Lw\nzDOwdi1cey20bRu7fEXnxhshOxs++QTatIldvoSkREduheHTT+H112G8m6YTgLFj4ZFH4OKLYfv2\n8m6NozKQnw/33GOGVYcOcN55UJlzcU2aBH/7G9xyC5x0Upns0ol+PHgX33vvlW87UoFvv4Xbb4ej\njoING0z8HY6SsmyZGRB/+hPccAN8/DEceSQccwz861+Ql1feLUwey5bB6NEwYAA89FCZ7daJfjx4\nov/tt7BmTfm2JRr79sHf/w59+8J11yW//s2b4dxz4eCDYfJkuPBC+POfYcWK5O+rqrJtm4nBDTdU\nLqGLxaxAF+CIEfDkk5CTA089BStXwhlnQGYmpNLET//+NzRrBg0aFH81aQIXXQRZWcW3++03OOcc\nqFHDInZq1iy7NqtqSr169+6tKUlurmr9+qrHH68Kqs8/X94tKs6mTaqPPKJ60EHWxrp1VevUUd2x\nI3n7yM9XPe001Zo1VWfNsmUrV9p+Ro1K3n6qMvn5qr/7naqI/Y5nnKG6e3d5t6psuOEGu2737y+6\nfP9+1bvusvMxZ075tC0cZ52l2qyZ6k03FX9deqlpBqged5zqJ5+o5uXZdmPG2PJ//StpTQFmqw+N\nLXeRD32lrOgvWGCn6/XXVQ87zMS/jNm5M8KKZcvsIqpXz9p4wgmqn36q+sUX9v2f//S/k7Vro69/\n6imr8+mniy6/805b/v33/vflCM9f/2rn8pFHVJ95xsT/6KPtpp5s1qyxm0yqMHCg6lFHhV+3aZNq\nrVqq11/vv77//lc1O7v4a9481d9+K1lb/bRn82bVRx8tNMS6dLEbG6jeeGPJ9h+CE/1k88YbdroW\nLFC9/XbV6tVVN24ss92vXGnG9VdfBRbk59uXESNMFGrWVL34YrugPfbvV01L82+BT5pkx3j00arv\nvmtPN8F8/73t54wzigvF9u2qBxxg26aSiFQ05s5VrV1bNTOz0CqcNMnEpWtX1f/9r+T7yMtT/fhj\n1SFD7Pd+4omS15kMcnPNcLnuushlzjrLrmk/gv3113Z8kV4HHqj60EOJ30yff97qmTs3dtnfflN9\n803VI46wbfr2LflNJwQn+slmzBh7VMvNNbeGZ/WXETNn2i5feTFXdeJEu2hAtWlT1TvuUF29OvyG\nl1+u2qiR6t69sXdywgkm3B06WN2HHKL67LPmHtqyRbV9e9V27cx6CcdLL9l277yT8HFWabZvV+3c\n2azCX38tum7GDNXGjW1d8I09HnbvVn3xRbM2QbVNG9WMDLs+QvdXHvz0k7Vr/PjIZT7+2Mp88EHs\n+k4/XbV5c7se33236OvNN1VPPNHqqldP9ZprVJcsia+9ffuq9ugR3zb5+ao//FAqT21O9JNN//6q\ngwbZ5/x81bZtzbddRnz0Yb4ZZU0etJ+tc2dzA0T0+QT45BMrP3ly9HIrV9oTw3332Y3tnXfsMRtU\nmzRR7dlTtUYN1W+/jVxHbq5qt26qHTv6u8mUlNmzVf/2t/CvKVMKLeWyZM0aE9ZwbXrrrci/V36+\nPZFVq6b673+HLzNvnmrr1ibSM2b4b9Pu3ar33msWMqj26mVt2bdPddEie2q95pq4D7UIy5apfvll\nyep4/XVr38KFkcvs32+GyRlnRK9ryRK7nu+6K3q5+fNVL7vMnqRE7EYxb17sti5caG196qnYZcsI\nJ/rJZN8+66gM9sFdd509hiezkzQKf79proLq7W3GW+ePX0Hbu1e1YUPV0aOjl3voIbscli8vuvzb\nb61TsXp1fxf4lClWz9ix/tqXKJ4bJNrj+6GHqr7wguquXaXbFo8dO6y/J1qbmjZVve021Zycott6\nT0kPPBB9HytXmpuncePiv1UkLr3U6j71VLtZhLrfrr3Wft9oYhuOUBcjqK5YEV8dwYwZo9qgQXG3\nYig33WQGSLSnk2uuMSGP1UflsXat6t13W6dsmzaxr5k//tHO2bp1/uovA5zoJ5OsLDtV//hH4bIZ\nM2zZpEll0oTnjnhFQfWq0TH+EOE491yz8iL9mfLz7clh8ODIdezZ439/mZn2dFBafR7BbpDFi826\nDn6tXq06YYJqnz72GzVvbhafXwFIhPx81QsvNEv9o4+Kt2nNGhPIM8+0MjVqWPk5c8xdU6eOuddi\nCZ6qiX3jxqpHHhnbLzx+vJ2DO++MXObXX62+k0/2d6z79xd3MV57rX3+85/91RGO/v2jX4Me8+bZ\nvp55Jvz6jRstAuiyy+Jvw7//bXU/+GDkMrm5du2demr89ZciVU/0f/3VfuSSPmKG45VX7FQF+/xy\nc1VbtDBBjcb48eZiKQmbN+sD1e9RMKM7brwO2kgugW++sfXjxpWomQX89JMJ2w03JKe+YPy4QYLL\nzpxprgARs/xGjLAO79DXH/5QMqtt3Dg7h/fdF7vsf/9rER9eOF+DBqqtWsW3/3ff1ZgRIIsW2T4G\nDSoeAhnK449bfZ9/Hr3cW2+pHnywle3UyTozPZdV9+6FLtB48Z6mb7rJX/levewVjgcDLtD58xNr\nyxln2G8SyUjwnmZTrO+q6on+zp3q6/E4EX7/e7OEQl0qo0eb6ySS/9rzp9eu7a+HPxJ//avexBMK\nCUaK7thhbYgUFXHlldaZtX174m0M5eKL7Y8Tq88hXl5+ObYlFo4lS8wa7dDBOqNDXzVrWiy1H0s7\nlAULzLIcMiS+7bdsMbHt0yf2DSwc0WK9d+82EU5LK+5KCseePdZR36NH+GPIz7f/lhd5Es7FeO+9\ndnNN5ObpPU1PmOCv/DPPWPlQ//vevXYDHTYs/jZ4LF5sT2JXXhl+/bnnmhuoLPqt4qDqib6q/XnP\nOy/x7SPRp48JQiiTJ9spDGfJr1plboXu3e1RsHPnxEW1Xz+9vOm7ChbxlRCnnWadz6H+3N277YZ2\n4YUJVhyBr77SmJEY8TJvXnxukHh49VX/lnowu3apHn64asuW5sIpS/buNWu3adPivvQrr7Tj+fRT\n//VNnGjbvPpq0eW5uWb4gOoFF0R2KWVnW5mXXorvOFQLn6aXLvVXfsMGu1GHPhm89prVM3Vq/G0I\n5rrr7Gky9Glhyxa7Bq+9tmT1lwJVU/QzM0ugihHYu9curltvDb+uUSMLiwxm/34bZFK/vurPP5sV\nV62a3ZDijWFftEgV9MzuixXMGEsILzLCG0XrMWGCLZ82LcGKI5Cfb1E84W6WibBjh4UaxusG8Yvn\nkxexQW1+uewy2+azz5LfJj8sXWpPm/37m4tEtfA3ve22+OrKz7d6DjywMEBh925zd4B1XkYLIPB+\n88zM+I/jqqvM+Ijn/3HGGRbJ47mu8vPNyOreveRjRTZutH6p0GN58cXw/6MUoGqK/o032mN2MkP1\nZs/WqB22551nj9DBPtM77rBt3nyzcJn3aPzyy/Ht/7bbVKtX1xOO2atg95iE2LTJog1uv73o8sxM\newIojfDG++83QSxJRIfHRRdZXdOnl7yuSMR7Y/n73zVmJ2lZ8Pbb1o5bbjE3VoMGNkgulh8/HF7/\nzj332DVz1FF23p991t/2t9xiRtKWLfHtt3fv+H2XH3xgbf34Y/v+2Wf2/bXX4qsnEmPHWn1TphQu\nO+ooe7JLwQGIVVP0vbC3X37xVz4/P7bY/e1vGjaU0eOf/7T1Xgey18kTav3n5ppbok4df3HA3jat\nW6uefHJBIAoUGnRxc/zxFsboXbCrV9sTSGmJ1i+/aFL6WbxH9nvvTUKjYuC5kIYOjX5txNNJWhZ4\n7pd27czfvHJl4nWdfbYZT126WOd3PBFq335b3OCJhfc0/cc/xtfO334zg8uLbhg2zG7YyfK1791r\nAxS7dbP/4pIldmyPP56c+pNM1RR9z48cayBSgLv7TtFjG87S3P1R7tqjR9ufKNKdfccO3VO7saY3\nW6P/fHGTRfR06xY+znfdOrsou3TxF98/dWrBU0anToWin/DgSW/Y+IIF9v2xx7RYVFKyGTLEojwS\nsYzmzbMY85o14+8kLQme8RCus3j9evP7p6X57yQtC/bssdG1wZZvoixfbmLfuHF8g8BU7UZ50EGq\nI0f638Yb4R5PjiiP66+3tnpD1uPt4I+FZ9S99JIZR9WqlX3fjU+qpuhv3KjxDAwaXO8HBdXX/y/K\nsPaePW24dhQ+H3C3guqtbd+yKJhog1ymT7fH5Ysuit3A886zTro9ezQtzf6DYN0ECbF6deEfIz9f\nNT09cnKrZOH1JXz9tb/y+fn2tDR0qG3nDZHfsKF02xnahtCw0AULzADwBoSdckrJIrJKg3Xr4uuP\niMY339go20S45hr73fwOinvhhfie0IOZM8e2bdnSnk6SPTYkP99cZQccYIO2hg9Pbv1JpGqKvqpZ\nX7FGn6qq7tmjHVmqoNq69q/hr8/duy106447olZ1U+ZPCqqX8qq/fDz33qsxfY9bt5qb4eqrNT/f\nmuHlavrmm9i7iMiAARbx8cMPhRZMabJjh7lBrrgierm8PIsaSU+3dh14oOrDD5dOZkk/BA8AGz7c\n2lSnjnU4JnzXrSJMm2bn6/33/ZW//HKLdEvkaTA/38JMQfXqq+Pf3g/ffVf4mP3226WzjyRQdUV/\n0CC7M8cgf9Zsrc0eHdjA0hvcf02YRzbvx37vvah1deuaa6Pc2/rM852ba+6KmjUj+z69ePTvvy8Y\ngnDmmVryp/cnnrBKTj7ZRGzr1hJU5pOLL7Ye6Gg54b0bYUaGZTRNcgbChJg7185Ry5bWKV2WTxsV\nmX37zCXqNww4I6NkcfXPPWf/pcWLE68jFhdcYK7beEamlzFJFX0gE1gMLANuC7O+HTAdmAfMANoE\nrXsM+CnwOifWvkos+ldeGd0HH2D9U28qqD570wo9s/p7Wr/GnuKuur/8xU5RlE6xVasKjYD+/eKw\nVLZsUT32WC3oGApt78CB5vvPz9ecHC0IzgALGkmYZcsKGxxrNHGy8PL6B6exCCbY5ZVqURFr16b0\nHz1lueQSC3mMdfPevduiykoSTJCXFznLbLLYuzc1MpFGwa/ox5wuUUSqA88Dw4F0YJSIpIcUexIY\nr6o9gPuBRwLbngz0AnoC/YCbRaSRz0m9EqNrV5vOb8OGqMVyvl8NQJsBbXnsvHnsy63GvbfsKlpo\n9mxo2TLqDPWffWbv3brBxk3iv51NmsCUKXD22XDrrXDjjTYpNNjcmV9/DZdcAiJs22aLO3Sw982b\n/e+mGB07Qo8e9vmSS0pQURwMHgzt2tmk8qGsXw/nnw+HHQbPPw8SxzksC1q1gjp1yrsVFY+RI2Hr\nVpgxI3q57GybDrJPn8T3Va0aHHRQ4tv7oXZtaNGidPdRRviZI7cvsExVl6vqPmAicHpImXTgi8Dn\nL4PWpwMzVTVXVXdhTwKZJW92FLp2tfdFi6IWWzV/KwBt21Wj4z3nM4bnefUfdfnpp6BCs2fbxRhF\niKZOtevt2GNh48Y421q7NkyYANdfD888A6NGwd69MH68XcgXXADYfwdMN6GEog9w9dXQrx+ccEIJ\nK/JJtWo2V+i0abB6deHyvDw7xq1bYdIkm1fUUTkYOhTq14f33otezpt3uiSi74gLP6LfGlgV9D0n\nsCyYbGBk4PMIoKGINA8szxSReiKSBgwB2obuQESuFJHZIjJ7QwwLPSZ+RD8/n5z//gZA27ZAp07c\ndfJcGrONm2/MtTK7dsHChVEvxrw8+PxzGDbMjICtW2H//jjbW62aTSr++OMmfJmZ8MYb9qdpbafZ\nE/3mze0BocSi//vfw3ffQfXqJawoDi6+2J5k3nyzcNkjj9iN4LnnoHv3smuLo/SpUwdOOgk++CD6\nxO6zZsEBBxRc647Sx4/o++FmYLCIzAUGA6uBPFX9DJgMfANMAL4Fil0BqvqSqvZR1T4tSvoI1bat\nWRjRRH/FClb91oKa1fMKntia3XYld+v9TJ1Wg6lTsRns8/Ojiv6sWbBlS6HoA2zalECbReCWW0wQ\n//MfWLnSRDKAJ/pNmkCzZkkQ/fKgY0cYONBcPKrw73/DvffCeefB5ZeXd+scpcHIkea+++67yGVm\nz4Yjj0w9t14lxo/or6aodd4msKwAVV2jqiNV9QjgzsCyrYH3h1S1p6oOBQRYkpSWR0IEunSJLvrZ\n2eTQhjYH7KeadwaOPppr+/xAx5r/4+ablbwffrTlUUR/yhQz1E84AdLSbFmJHlTOP98qveIKOOOM\ngsWVQvTB+hB+/hkmTzax79QJ/vY394evrJx0EtSqFdnFs3On/U+da6dM8SP6s4DOItJBRGoB5wIf\nBhcQkTQR8eq6HRgXWF494OZBRHoAPYDPktX4iHTtGl30s7JYRVvadKhZuEyEWrdcz6P7b+Knn4TX\n3q5nj5wHHhixmqlTzUhp3rxQ9OP264dy/PHw0ktQt27BIk/0Gzeu4KL/u9/ZcY0caY9EkyZBw4bl\n3SpHadGokbkp33vPnu5CmTvXljvRL1Niir6q5gJjgKnAImCSqi4QkftF5LRAsWOBxSKyBDgAeCiw\nvCbwlYgsBF4CLgjUV7p07Qo5ObBjR/j1WVmsqnkIbduF+LRHjuTMg2dzdKN53D37dHb2HBhxF5s3\nww8/mGsHCt07JRb9MGzdai7SOnWgaVNzKVVIGjUywd+3D55+GjIyyrtFjtJm5EhYscKeXn/+ueg6\nrxO3d+8yb1ZVxpdPX1Unq+qhqtpRVR8KLLtHVT8MfH5HVTsHyoxW1d8Cy/eqanrg1V9Vs0rvUILw\nOnMXLw67On9uNqvzWhWPxKxRA7nhesZuv4J1eS14fNe1EXcxbZq5/DMDsUhJce9EYOtWc+1ABbf0\nAZ54wvourrqqvFviKAvOO89+6zfftP/lqafCl1+ahT97toVDt2pV3q2sUiSrIze1iBbBs2ULG1bt\nYV9+TYvcCeXyy+nX6GfOZQJPfnsUOTnhdzF1qgnxkUfa9+bN7b00LP1t28y1A4Wi74X0VzgOPND6\nLpwfv2pQp47126xcCffdB99/D8cdZ9b99OnOtVMOVE7R79gRatQIL/qBTlyIMOaqUSO46ioern4P\neVqNu+8uXkTV+ltPOMF2A1Czpt0EysLSz8+P7LlyOFKSli0tWmvlSnj5ZRuPsn49DBhQ3i2rclRO\n0a9ZEzp3Di/6gU5cILylD/Dgg3SY+x7XXy+88YZFbwazYAGsWVPo2vFISys9n36w6EMFd/E4qi51\n6sDo0fDTT+beue668m5RlaNyij5EDtvMyiKnoWWRiCj6tWpB9+7ccYeJ7E03FQ0+mDLF3r1OXI8W\nLZzoOxy+qFbNXDwuxUWZU3lFv2tXy2Gzb1/R5dnZrEo7glq1CjtfI9Gkibkhv/gCPvmkcPnUqZCe\nXtw9lJZWNu4dcKLvcDgSo3KLfl6eCb/Hvn2wYAGr6namTRsKB2ZF4aqr4NBDbcDs/v2WnWHmzOKu\nHSgdS1+1qOg3bWrvFTZs0+FwlCuVW/ShqItn0SLYv5+c/IOiJc4sQs2alhbn55+t/+nf/7Z7R6hr\nBwot/XDjUBJl717bn7P0HQ5HMqi8ot+li70Hi36gR3bVjiaR/flhOO00yw587702iLROHRg0qHi5\ntDQT6J07S9DuELy0yqGWvhN9h8ORCJVX9OvXh4MPLir62dnk16nH6l9r+rb0wULKx441180bb1ga\n5aAsCQWUxqjc4BQMYDecevWc6DscjsSovKIPxXPwZGXxa9fB7N8vcVn6YIEGF15on8O5dqB0RuUG\nJ1vzqPCjch0OR7lR+UX/559tNJOqhWu2t3w68Yo+WPr3s8+Gc88Nv740LX0n+g6HIxnUKO8GlCpd\nu8KePTYKsFo12LKFVS16AVFnQIxI69bw9tuR15eVpd+0qRN9h8ORGJVf9MFcPLmW3HNVvcOAxCz9\nWJSlpb90afL24XA4qg5VQ/R//tlCakTI0dbUrh17YFYiNGxoIZ7OveNwOFKVyi36aWn2WrTIJu3o\n1IlV62vRpk3pJHkUSf6o3K0ESexhAAAgAElEQVRbLStE8Gh1J/oOhyNRKrfoQ2EEz5o10Ls3OTmJ\n+fP9kuxRudu2mZUffJNq1swGbe3ZEz501OFwOCJRuaN3wEQ/OxuWL4eePVm1qnT8+R6lYel7Mfoe\nblSuw+FIlMov+l26FCSfz+/Rk9WrK5alH5x3x8ONynU4HIlS+UXf68wF1h90BLm5pW/pl7boe5a+\nS7rmcDjixZfoi0imiCwWkWUicluY9e1EZLqIzBORGSLSJmjd4yKyQEQWicizImU8T54n+mlprNpv\nc3GWtuhv3lwQIVpioom+s/QdDke8xBR9EakOPA8MB9KBUSKSHlLsSWC8qvYA7gceCWx7FHA00APo\nBhwJDE5a64P49Ve45hr45puQFW3bWrKanj3JWW33m9J270DyBNmJvsPhSCZ+onf6AstUdTmAiEwE\nTgcWBpVJB/4v8PlL4IPAZwXqALUAAWoC60ve7OLUrw+vvmrvRx0VtKJaNZsJpUsXVi23RaVt6YN1\n5rZsWfL6nOg7HI5k4se90xpYFfQ9J7AsmGxgZODzCKChiDRX1W+xm8DawGuqqhabw1BErhSR2SIy\ne0OCoS/161u646lTw6y85RY49VRycizevXnzhHbhi2SOyv3tNwvNDBX9Bg1sQnYn+g6HI16S1ZF7\nMzBYROZi7pvVQJ6IdAK6Am2wG8VxIlIsE72qvqSqfVS1TwtPNRNg2DCYPx9Wrw6/ftUqSm1glodn\n6SdD9L1c+qEhmyJugJbD4UgMP6K/Ggh2iLQJLCtAVdeo6khVPQK4M7BsK2b1f6eqO1V1J/ApMCAp\nLQ+Dl/L4s8/Cry/tgVmQ3KRr4VIweLikaw6HIxH8iP4soLOIdBCRWsC5wIfBBUQkTUS8um4HxgU+\nr8SeAGqISE3sKaCYeydZdO8OBx4IU6aEX1/aA7MguZZ+NNFv1syFbDocjviJKfqqmguMAaZigj1J\nVReIyP0iclqg2LHAYhFZAhwAPBRY/g7wX2A+5vfPVtWPknsIhYiYtf/55zYnejB5eeb2KW3Rr1UL\nGjUqfUvfuXccDkci+Mq9o6qTgckhy+4J+vwOJvCh2+UBV5WwjXGRmQmvvw6zZ0O/foXL16834S9t\n9w4kb1RuLNFfsKDk+3A4HFWLSjci94QTzOIPdfGsCsQflbalD8kblessfYfDkWwqneg3bw5HHlk8\ndDMnx97LwtJPVtK1WKK/fTvs31/y/TgcjqpDpRN9MBfP998X7egsS0s/We6dbdssHr9eveLrvKRr\n3o3B4XA4/FApRX/YMJsLfdq0wmXewCxvNGtp4ln6qiWrx0urHG5cgRuV63A4EqFSin7fviaWwS4e\nL1yzLNK9tWhhI2l37y5ZPeFSMHi4TJsOhyMRKqXo16gBQ4daZ65nbXujccuCZMXq+xF9Z+k7HI54\nqJSiD+biWb0aFgbSwuXklI0/Hwrz75S0M9eJvsPhSDaVWvTBrP28PJsit6xE31n6DocjVam0ot+2\nLaSnm19/3bqyG5gFycu/E030veVO9B0ORzxUWtEHs/ZnzoTFi+17Wbt3Smrpb9sWWfSrV7fOaif6\nDocjHiq16GdmWk76t96y72Vl6TdubJ3JJbH09++HXbuKp1UOxo3KdTgc8VKpRX/QIIvNf/tt+15W\nlr5IyVMxeLn0I1n64DJtOhyO+KnUol+3LgwebBZz3bqFo1jLgpKKfrQUDB7O0nc4HPFSqUUfzMUD\nZTcwy6Ok+Xec6DscjtKg0ou+F7pZVq4dj5Lm30mG6K9aVZhzyOFwxOZ//4s83WplwVc+/YpMly7Q\ntSt061a2+y0LS9+bMjE/H6qFuX2PHGnLv/8+8XY4HFWJs8+2iZC++qq8W1J6VHrRF4EffrAfsixp\n0cIEOS/Pwivjxa+ln58PO3YUj/JZt84mkgH49Vdo2TL+NjgcVYn9+yErC3JzLUCiLPsAy5JK794B\naNCg7EU/Lc3y/iQaXeM3egfC7yN4cvjPP0+sDQ5HVeLnn2HfvuIZeisbVUL0y4OSjsrdutVcMw0a\nRC4TLRXD1Klm3aelFZ9QxuFwFCcry96rV6/c/5lK794pL0o6KjdaLn2PSKKfn2+WfmamuZc++yyy\n39/hcBhZWTauJzPTRF+1bCP+ygpfMiAimSKyWESWichtYda3E5HpIjJPRGaISJvA8iEikhX02isi\nZyT7IFKRZFj60Vw7EFn058yxm01mpr3Wr4fs7MTa4XBUFbKzLeDj5JMtK6+XobeyEVP0RaQ68Dww\nHEgHRolIekixJ4HxqtoDuB94BEBVv1TVnqraEzgO2A18RhUgGZZ+oqLvPZoOHQonnlh0mcPhKI6q\nWfo9exaGeVfW/4wfS78vsExVl6vqPmAicHpImXTgi8DnL8OsBzgL+FRVSzifVMWgeXN7L03R96IL\nQkV/yhTo3dt8+q1aQUaGLXM4HOFZswY2bTLR9zL0Vtb/jB/Rbw0ED/HJCSwLJhsYGfg8AmgoIs1D\nypwLTAi3AxG5UkRmi8jsDSXNR5wi1KljnbCl6d6pU8fSSwSL/rZt8O23hdYKmIvnP/+x0E6Hw1Ec\nrxM3I8PevQy9JZ3yNBVJVtfezcBgEZkLDAZWA3neShE5EOgOhH1gUtWXVLWPqvZp4flFKgElGZUb\nLa1yMKFJ1774wjpvg0V/2DCLPf7yy8Ta4nBUdrw+rx497N3L0DtzZvm1qbTwI/qrgeAkBm0CywpQ\n1TWqOlJVjwDuDCzbGlTkbOB9Vd1fwvZWKEoyKtePpQ/FUzFMmQING8KAAYXLjj4a6tevfI+rO3bY\nzayqsWsX7NxZ3q3wz6+/lncLYpOVBYccAo0a2XcvQ29l+8+AP9GfBXQWkQ4iUgtz03wYXEBE0kTE\nq+t2YFxIHaOI4NqpzCRq6efmhh9lG45g0Ve1zqfjj4eaNQvL1KoFxx1XdKL4is6uXWaVnX565Tkm\nv1x8sR13ReDHH61f6dtvy7sl0fE6cT3q1oVjj62cnbkxRV9Vc4ExmGtmETBJVReIyP0iclqg2LHA\nYhFZAhwAPORtLyLtsSeFfye15RWARNMrb99u7/Fa+osXW8IoL7NoMMOGwS+/wLJl8bcnFRk7Flas\ngMmTK6c1Fo2lS2HGjIoxl8LixXZT/uCD8m5JZHbutP9FsOiD/Wd+/tn+U5UJXz59VZ2sqoeqakdV\nfSiw7B5V/TDw+R1V7RwoM1pVfwvadoWqtlbV/NI5hNSlRYvE3Dt+8u54eEnXoNAqCfbne3g3gspg\nuaxdC48/btZup05w881Vy82zYUPFSRWwfr29p/J1N3++3Zi8TlyPyhq66cZoliJpadb7H28EQDyi\nH2zpT50Khx0G7dsXL9exo70qwwV8zz2WI2XsWHjsMRtEMy7UoVhJUS18eqwIv+W6dfaenW0361TE\n68QNtfS7dIGDD64Y5zkenOiXIt6o3HhdPPGK/t699qg/Y0Z4K99j2DCL7vntt8hlUp35803gx4yx\nm9iIETBwINx9d9UISd2xw7JBQsXoo1m3zuaLhqJJAFOJrCz7r4XOuSFi/5lp0wrPeWXAiX4pkuio\n3HhFH+DDD2HPnuiin5lpTx3/+U987Uklbr7ZOrjvusu+i5jF/+uvZvVXdjx34cCBNtlHqqcKWLfO\nLOgDDkhdi9nrxA2XZycz0/rYKtOcFE70S5FELX0/aZU9PNH/xz+gdm2bEzgSQ4ZYVE9F7ficMsWs\nxbvvLjxugL59YdQoE//KPlOYdy1dcIG9p/pvuW4dHHSQGSOffWZjSFKJvDx7egx17Xgcf7xl3Uz1\n8xwPTvRLEc/Sj7cz17P0/YZsAkyfbrHF9etHLtuggVmIqWpxRSM316z8jh3h2muLr3/4YXN1eE8A\nlRXvWjriCEsVkOq/5fr1FrI5bJilOZgzp7xbVJRly+zpN7QT16NxY+jfP/XPczw40S9FSuLTFykc\nKBINL/9OXl74UM1Qhg2DefMs10hF4rXXYMECc+GEmxCnfXu4/noYPz71hCWZeNdSWlrqpwrIy7Ob\n1AEHWPI/kdQTz0iduMFkZtp4g0qSIcaJfmnSpIk9GiZi6Tdq5C//fbCbI5o/P7RMqnaqhWPHDnPp\nDBxo8/5G4o47TAxvuin1OzgTxRP9Fi0KUwX8O0VHwHihpa1aWXt79049N0lWlnU0d+0aucywYXY9\nVZYZ6NwkKqVItWqWbTMRS9+PPx8KRb91azj88NjlMzLsT/jJJxb5Upo0bJiciVsef9zcBP/6V/RJ\nLRo3hvvus8ied94pTCsdTJ061vdRUdmwwZ50GjQoTBUwdSoMH17eLSuOF67ZqpW9DxsGjz4a+/r2\n5n0OR4MG8c05HWvyoKwsc5NFuyZ69y6cge688/zvO1Vxln4p07IlLFkS3zbxiH7DhoWz/fiZ5ccL\nQ3vnHdtHab6GDrU/XUnIybEO2nPPhX79Ype/8kobq3D22eHbdOCBhX0mFZGNG02ARFI/VUCo6Hsz\nuU2fHnmbvDw45pjI11S/fjZGww+zZ1sncrTzk50d3bUDdtMYOtRGf+/a5W/fqYyz9EuZUaPgzjvt\nETxaZE0w8Yi+iF2M6aHT2kThgQfsQi9NF8jy5fCXv1hUkRdpkgh33WU3jkce8Ve+Zk37k7/3XvF1\na9fCE0+Y6Jx5ZuJtKk82bCgMEAC7gd94o6UKaNeu/NoVDm80rif6/fqZ23Lq1Mjnf9w4Cym+8cbi\ncfPr11ufzl//CjfcEH3fqlbH+vXW1zN/ftF8VGDncs2ayJ24wYwZAxMmmAFyzz2xy6c0qppSr969\ne2tlYvdu1bZtVXv1Us3L87dNRobq6aeXbrtKm7w81T597Nh3706sjjlzVEVUb701OW3at0+1USPV\nK65ITn3lwYABqscfX/h94UJVUH3xxfJrUyQefdTatnNn4bIRI1QPPlg1P794+e3bVQ84QHXgwPDr\n8/NVhw5VbdpUddOm6Pt+913b95ln2vtf/lK8zOef27rp0/0dz1lnqdavr7pmjb/yZQ0wW31orHPv\nlDJ161o44Zw58NZb/raJx9JPVapVK4yb//Of499e1TpkmzWzDtpkULOmxV1XhJGskdi4sail76UK\nSLUOUjD3ToMGRcOIMzNh5UpLZBaK13czdmx4V6UIPPmk/T8efDDyfvftgz/+0Z5+J040F9h99xWO\nf/EInTglFo8+anXffbe/8qmKE/0y4LzzrDPojjv8hddt3eovRj/VOeYYOOMMc814j/p++fhjm/Tl\nvvuSey4yM+1GFE50KgIbNhSGAkNhH8306amXKmDdukLXjkekJGZe382oUTbYLhI9esBll5nr8L//\nDV/mhRcs/v7JJy0yZ+xYGyPw8MNFy2VlQZs2hVObxqJjR/jDH8wFNW+ev21SEj+PA2X5qmzuHY8Z\nM+xR8qGHopfLyzOXxj33lE27SpvFi1Vr1FD9/e/9b7Nvn+phh9lr377ktmfFCvsd/vzn5NZbFuzb\nZ22/776iy995x5Z/9VX5tCsSxx5rrppQunRRHTas6LKLLlKtXVv1l19i17t6tWq9euZuCWXzZtVm\nzcwNFOwiCld/t26qp5zi50gK2bTJ3EsnnhjfdmUBzr2TWgwebKmAY1m927eb66Giu3c8Dj0Urr4a\nXnrJf56Yl1+2POyPP168862ktGtn0T2p6A6JxaZN9h46o2iqpgrwRuOGMmyYBTbs2WPf58yBv//d\nOlzDZYgN5aCD4NZbLQItNI/Ugw9a8sEnnijqInroIXM5eq7CvXth0SL/rh2PZs2sI/ezz1LvfPvG\nz52hLF+V1dJXLbR6r7oqcplffjGrbdy4MmtWqbNhg2rjxqonnRS77NatqmlpZiWG68xLBtdfr1qn\nTuIdzOXF/Pl2bbz9dvF1Rx9tHeepRNOmqtdeW3z5p5/acUydar/xkCH2m2/d6r/unTtVDzpItV+/\nwutk2TLVmjVVL7ss/DZ33WX7/f571R9/tM///Gf8x/Xbb6qdOqkefrjq/v3xb19a4Cz91MOzel9+\n2VIKhCOeDJsVhbQ0C72cPDn2xB+PPGKdlZE685LBsGFm6VW0Sa+DR+OGMmxYaqUK+O03s7jDWfrH\nHGODoaZMSbzvpn59s+q//x4mTbJlt99uT4YPPBB+m1tvtZQQ//d/MHeuLYvX0gcbHPfYY/YfrpDz\nOPi5M5TlqzJb+qqFVu/w4eHXf/mlWSBffFGmzSp19uxRbd9etUcP1dzc8GV++cX8rhdeWLpt2bXL\n9nPjjaW7n2QzaZJdG/PmFV/3ww+27q23yr5d4fjf/6w9L78cfv3QoYX9Non23eTm2vXUvr39X8L1\nd4Ty4otW7tBDLfzSbxh1KPn5qoMGqbZsaaGmqQDO0k9N0tJssNann4bP5RFPWuWKRJ06FvI2b54l\nRQvHnXeadf/QQ+HXJ4t69czaTNWRrJEITrYWSq9eFoWSKscUOho3lMxM67cpSd9N9eqFcyWfcoqN\ntr755ujbXHaZpStZssSs/ETThHjhoxVyHgc/dwYgE1gMLANuC7O+HTAdmAfMANoErTsY+AybVH0h\n0D7aviq7pa9aaPXWrq3avHnRV4MGZoksX17erUw++fmq/fub3zX0uJs3t+O+886yacuTT9r+Vq4s\nm/0lgz/9ydocySo+91zVVq3817drl0WwhPstor1Gj45d94cfWltnzQq//qefbH0y+m5OOsnqevVV\nf+W9PoWrry7ZflVVR42y/qGNG/1vk5kZ+dyWJCoIn5Z+zDQMIlIdeB4YCuQAs0TkQ1UNjsV4Ehiv\nqm+IyHHAI8CFgXXjgYdU9XMRaQBUuQnSQ6lTB95/H159NfwgoVat/EUxVDREbIDac8+FjylPS4Nb\nbimbtmRmmlU4dSqMHl02+ywpGzea3zuSVXz44TYYad++8OmnQ1m1Cn76yfoDOnXy14avv4YPPrB+\nqWh4lv4BB4Rfn54OTz8Np55a8r6bl1+2/9PFF/srn5lpsfxDhpRsvwC//72lZ5g1y19q802brC9j\n8GDo1q34+jL538e6KwADgKlB328Hbg8pswBoG/gswPbA53Tgaz93H+9VFSx9R/mTn6/aurUN068o\njBplUSOReP55s2DXrfNX3zffWPlPP/Xfhscft222bIle7v77rdzevf7rrohs3WrH+cgj/spPn64F\nkUvJhiT69FsDwZPQ5QSWBZMNeJnORwANRaQ5cCiwVUTeE5G5IvJE4MnB4ShXRMwymzbNZuWqCISO\nxg3FS7O9ebO/+rxywXMyxMJ7Iog0GtZj3TqrtyKnsfZD48ZmnXuTscTCK5dI1FCySFZH7s3AYBGZ\nCwwGVgN5WBbPQYH1RwKHAJeEbiwiV4rIbBGZvSFVYs4clZ5hw6zj/Icfyrsl/vDSKkeiLEV/2bLo\n5cKlYKis9OxZmMcnFllZdl4iub3KAj+ivxoITnLaJrCsAFVdo6ojVfUI4M7Asq3YU0GWqi5X1Vzg\nA6BX6A5U9SVV7aOqfVqEC0J2OEqBE06w6I2KMrIyNK1yKImKvjflph8OOcTeY1n6kUbjVkYyMiwa\nyE9erays2Pn7Sxs/oj8L6CwiHUSkFnAu8GFwARFJExGvrtuBcUHbNhER71I9DovgcTjKnaZNLcd7\nqoQ5RkM1tqXviXe8oh9PeHD9+hYa6cfSL09rtizp2dPmfPjpp+jl9u2z1A8pL/oBC30MMBULu5yk\nqgtE5H4ROS1Q7FhgsYgsAQ4AHgpsm4e5dqaLyHyskzdGv7/DUXYMG2aRF/FOaVnW7Nplo1yTbel7\n8zjHQ6dOzr0TjOefj+XiWbjQotbK058PPn36qjpZVQ9V1Y6q6gn6Par6YeDzO6raOVBmtKr+FrTt\n56raQ1W7q+olqupzsjOHo/TJzDQrOlZ6iPLG6+qKZuk3bmwd1Fu2+Ktzy5b4/PkeHTtGd+/s3Gk3\nqaoi+u3b24xgsUTf68RNeUvf4ajM9OljwpfqLp5oo3E9qlUzF088ln4iot+pk00zGGm+2FijcSsb\nIibksSJ4srJsUqXOncumXZFwou+o0lSvbh26U6em9mxanqUfK86hWbOyEX2weZDDETo3blUgI8NE\nPz/K0NPsbOjePX53WrJxE6M7qjyZmZapsU8fm2mprKldG155xbKwRsKPpQ/xi36HDv7KBhMcq9+9\ne/H1sUbjVkZ69rQnn+XLw49uVjVL/3e/K/u2heJE31HlGTHCEuDt2FH2+87Ntf6Ezz7zJ/qxLP14\n3TvxhGt6dOxo75E6c6uaeweKduaGE/1Vq6wPpbw7ccGJvsNBkyaFOdnLGlVo2DB23PuGDfYU0qhR\n9HLNmsWOrAFzQyTakdukiWX0jCb61arFfiqpTBx+uLltsrLgrLOKr0+VTlxwPn2Ho1wRMcs5llB7\nMfqxkpP5de/s2GHCn4joQ/SwzXXroGXL8vddlyV16kDXrpE7c73InnDusLLGib7DUc74iXuPNRrX\no1kzm30tWociJJaCIZhoYZtVaTRuMBkZkcM2s7Ptd27YsGzbFA4n+g5HOdOxo3UA5uVFLhNrNK5H\ns2bmMvIm44lESUW/UydYudIGjIVSlQZmBdOzJ+TkFE5gH0wqpF/wcKLvcJQznTrZEP3VqyOX2bjR\nv6UPsV08yRD9/HybtSqUqpSCIRivkzbUxbN9uz0VpUInLjjRdzjKHT+ZK2OlVfYoK9H3InhCXTyq\nVdfSj5SOYf58e3eWvsPhAGLnqM/NtUgbP6LvN+laIhk2g4l0o9qyxfLLVEXRb9nSktGFWvreTcBZ\n+g6HA4DWrW16w0iW/ubNZkEn073j5edJVPRbtLBOydA2V8XRuMGEy62fnW2/S5s25dOmUJzoOxzl\nTPXqlqc+kuj7HY0L8bl36tWzUMNE8EJNQ59OquLArGB69rRsmsEd3FlZZuWXdC7gZOFE3+FIAaKF\nbfodjQuFlnusTJuJ5t0JJlybq2IKhmAyMswdt2iRfc/NNZ9+qvjzwYm+w5ESeFZzuKRvftIqe9Sq\nBQ0a+LP0kyH6v/xSdI5hZ+nbu+fiWboU9u51ou9wOELo1MkSdnk+8WDice+Av1G5yRL9/fstr4zH\nunV244lnNq7KRKdOlj7Z68xNtU5ccKLvcKQE0cI247H0wb/oJ9qJ6xEubNMbjZsq/uuypnp16NGj\nUOyzs6FmTUvRkCo40Xc4UoBIce9gln7DhpaC2Q9+Mm0my9KHojeqqhqjH4wXweOlU05Pt6efVMGJ\nvsORArRrZ1ZiOEvfbwoGDz+WfqIZNoM56CCL/gkV/araieuRkWH5j1atMks/lfz54ETf4UgJatUy\n4Y/k3vETueMRS/T37LHOxZKKfrVqFmoa/HTiLP1CkZ8yxc5HhRR9EckUkcUiskxEbguzvp2ITBeR\neSIyQ0TaBK3LE5GswOvDZDbe4ahMdOoU2b0Tr6W/ZUvk6R9LmoIhmOCwzbw8u0FVddHv3t36NMaP\nt++p1IkLPkRfRKoDzwPDgXRglIikhxR7Ehivqj2A+4FHgtbtUdWegddpSWq3w1HpiJRXPxFLf98+\n2L07/Ppki74XarpxoyVhq+qi36CBnZf//Me+VzjRB/oCy1R1uaruAyYCp4eUSQe+CHz+Msx6h8MR\ng06dzEIPdc0kYulDZBdPMkW/Y0dzF61d62L0g/GEvm3b5JznZOJH9FsDQZG45ASWBZMNjAx8HgE0\nFJHmge91RGS2iHwnImeE24GIXBkoM3uDF5/mcFQxwkXD7N5toloaol/SkE0o2uaqPho3GM+Pn2r+\nfEheR+7NwGARmQsMBlYD3pQQ7VS1D3Ae8LSIdAzdWFVfUtU+qtqnRTzPsQ5HJSJc2KZnA8Xzt4iV\nadNL0ZAs9w4UFX1n6ae26PuZGH010Dboe5vAsgJUdQ0BS19EGgBnqurWwLrVgfflIjIDOAKIMQ20\nw1H1OOQQew+29OMdjQtl6945+GCbsH3ZMmjc2JY5Sx/697cb4vDh5d2S4vix9GcBnUWkg4jUAs4F\nikThiEiaiHh13Q6MCyxvKiK1vTLA0cDCZDXe4ahM1K1r6XeDRT8RS9+P6NeoYR2OJaVGDWjf3p5O\n1q+3OpNRb0WneXPLuzNgQHm3pDgxLX1VzRWRMcBUoDowTlUXiMj9wGxV/RA4FnhERBSYCVwb2Lwr\n8KKI5GM3mEdV1Ym+wxGB0HTFJbH0I2Xa9EbjJitVghe2Wb26c+1UBPy4d1DVycDkkGX3BH1+B3gn\nzHbfAN1L2EaHo8rQqRN8/HHh90REv149G+wVzdJPZkRJp07wzTfQqJFz7VQE3IhchyOF6NTJ3CQ7\ndtj3DRvMgo4na6VI9FG5yRb9jh1t8u8FC5ylXxFwou9wpBBeBM/y5fa+caP5h6vF+U+NlnRty5bk\nhGt6eBE8bjRuxcCJvsORQoTG6sc7GtejLC19r83gRL8i4ETf4UghPEvfE/14R+N6lKXod+hQ2Cns\nRD/1caLvcKQQjRpBy5alJ/r795v/PZmiX7u2pRsA15FbEXCi73CkGMFhmyVx74QL2dy6tXB9MvFc\nPM7ST32c6DscKYYX956XZ9Z6opb+zp2WbTOYZI7GDcZzSznRT32c6DscKUanTpCTY5kr8/MTt/Sh\nuLVfWqI/YIC107l3Uh8n+g5HitGxo+WnnzXLvidi6UdKuubdBJIZsglwySV2o0qluWAd4XGi73Ck\nGJ5//Ntv7T1R9w4UF/3SsvRFnOBXFJzoOxwphif6331n7yVx75SV6DsqDk70HY4Uo1kzS1M8e7Z9\nL4mlH8mnH09aB0flwom+w5FiiJi1v2ePfU+2e6dJE8vn46iaONF3OFIQz8VTv77l2Y+Xxo3t5hFO\n9J1rp2rjRN/hSEE80U/EygdL0BYu6dqWLU70qzpO9B2OFMQb7FSSKaPDif7mzckP13RULJzoOxwp\nSEktfQiff8e5dxxO9B2OFMQT/ZJY+k70HeFwou9wpCCtWpngd+iQeB2hSdfy853oO3yKvohkishi\nEVkmIreFWd9ORKaLyLVgrW8AABPYSURBVDwRmSEibULWNxKRHBH5S7Ia7nBUZkRg7lz44x8TryPU\n0t+xw4TfiX7VJqboi0h14HlgOJAOjBKR9JBiTwLjVbUHcD/wSMj6B4CZJW+uw1F1aN3aJjlPFM/S\nz8+3757V70S/auPH0u8LLFPV5aq6D5gInB5SJh34IvD5y+D1ItIbOAD4rOTNdTgcfmnWzBK3bdtm\n3z2r30XvVG38iH5rYFXQ95zAsmCygZGBzyOAhiLSXESqAWOBm0vaUIfDER+hmTZd3h0HJK8j92Zg\nsIjMBQYDq4E84BpgsqrmRNtYRK4UkdkiMnvDhg1JapLDUbUJTcXgRN8BUMNHmdVA26DvbQLLClDV\nNQQsfRFpAJypqltFZAAwSESuARoAtURkp6reFrL9S8BLAH369NHQBuzfv5+cnBz27t3r/8gclZ46\nderQpk0batasWd5NSUmc6DvC4Uf0ZwGdRaQDJvbnAucFFxCRNGCzquYDtwPjAFT1/KAylwB9QgXf\nDzk5OTRs2JD27dsjIvFu7qiEqCqbNm0iJyeHDiWJa6zEhGbadD59B/hw76hqLjAGmAosAiap6gIR\nuV9ETgsUOxZYLCJLsE7bh5LZyL1799K8eXMn+I4CRITmzZu7p78ohLP069WDOnXKr02O8sePpY+q\nTgYmhyy7J+jzO8A7Mep4HXg97hYGcILvCMVdE9EJ7ch1ydYc4EbkOhyVllq1LDVzsKXvXDsOJ/o+\n2LRpEz179qRnz560atWK1q1bF3zft2+frzouvfRSFi9eHLXM888/z1tvvZWMJjscQNFRuS4FgwN8\nuneqOs2bNycrKwuA++67jwYNGnDzzUWHHqgqqkq1auHvo6+99lrM/Vx77bUlb2wZk5ubS40a7jJK\nVUJFv3Pn8m2Po/ypeJb+DTfAsccm93XDDQk1ZdmyZaSnp3P++edz+OGHs3btWq688kr69OnD4Ycf\nzv33319QduDAgWRlZZGbm0uTJk247bbbyMjIYMCAAfz6668A3HXXXTz99NMF5W+77Tb69u3LYYcd\nxjfffAPArl27OPPMM0lPT+ess86iT58+BTekYO69916OPPJIunXrxu9//3tULRJ2yZIlHHfccWRk\nZNCrVy9WrFgBwMMPP0z37t3JyMjgzjvvLNJmgHXr1tEpkPrxlVde4YwzzmDIkCEMGzaM7du3c9xx\nx9GrVy969OjBxx9/XNCO1157jR49epCRkcGll17Ktm3bOOSQQ8jNzQVgy5YtRb47kouz9B2hVDzR\nTzF+/vlnbrzxRhYuXEjr1q159NFHmT17NtnZ2Xz++ecsXLiw2Dbbtm1j8ODBZGdnM2DAAMaNGxe2\nblXlhx9+4Iknnii4gTz33HO0atWKhQsXcvfddzN37tyw215//fXMmjWL+fPns23bNqZMmQLAqFGj\nuPHGG8nOzuabb76hZcuWfPTRR3z66af88MMPZGdnc9NNN8U87rlz5/Lee+8xffp06tatywcffMCc\nOXOYNm0aN954IwDZ2dk89thjzJgxg+zsbMaOHUvjxo05+uijC9ozYcIEfve737mnhVIiONOmE30H\nVET3TsASThU6duxInz59Cr5PmDCBV199ldzcXNasWcPChQtJTy+an65u3boMHz4cgN69e/PVV1+F\nrXvkyJEFZTyL/Ouvv+aPgdSLGRkZHH744WG3nT59Ok888QR79+5l48aN9O7dm/79+7Nx40ZOPfVU\nwAY3AUybNo3LLruMuoHJWJv5UIYTTzyRpoFeQVXltttu4+uvv6ZatWqsWrWKjRs38sUXX3DOOecU\n1Oe9jx49mmeffZZTTjmF1157jb///e8x9+dIDM/S37MH9u51ou+oiKKfYtSvX7/g89KlS3nmmWf4\n4YcfaNKkCRdccEHYOPJatWoVfK5evXpE10bt2rVjlgnH7t27GTNmDHPmzKF169bcddddCcWz16hR\ng/xAisbQ7YOPe/z48Wzbto05c+ZQo0YN2rRpE3V/gwcPZsyYMXz55ZfUrFmTLl26xN02hz880Xej\ncR0ezr2TRLZv307Dhg1p1KgRa9euZerUqUnfx9FHH82kSZMAmD9/flj30Z49e6hWrRppaWns2LGD\nd999F4CmTZvSokULPvroI8CEfPfu3QwdOpRx48axZ88eADYHFKJ9+/b8+OOPALzzTuRhGNu2baNl\ny5bUqFGDzz//nNWrLUvHcccdx9tvv11Q3+ag5O4XXHAB559/PpdeemmJzocjOk2bwr59kJNT+N1R\ntXGin0R69epFeno6Xbp04aKLLuLoo49O+j7+8Ic/sHr1atLT0/nTn/5Eeno6jRs3LlKmefPmXHzx\nxaSnpzN8+HD69etXsO6tt95i7Nix9OjRg4EDB7JhwwZOOeUUMjMz6dOnDz179uTPf/4zALfccgvP\nPPMMvXr1YkvwFEwhXHjhhXzzzTd0796diRMn0jkQIpKRkcGtt97KMcccQ8+ePbnlllsKtjn//PPZ\ntm0b55xzTjJPjyMEz7Jftqzod0fVRbyojlShT58+Onv27CLLFi1aRNeuXcupRalFbm4uubm51KlT\nh6VLl3LiiSeydOnSCtcROnHiRKZOneorlDUa7tqIzrvvwllnwX332WvOHDjiiPJulaM0EJEfVbVP\nrHIVSykc7Ny5k+OPP57c3FxUlRdffLHCCf7VV1/NtGnTCiJ4HKWHZ9n/979FvzuqLhVLLRw0adKk\nwM9eUXnhhRfKuwlVBif6jlCcT9/hqMQE+/Rr1IAGDcq3PY7yx4m+w1GJ8UT/11/ts0tM6nCi73BU\nYurVA29iMReu6QAn+g5HpUak0Np3/nwHONH3xZAhQ4oNtHr66ae5+uqro27XIOBAXbNmDWeddVbY\nMsceeyyhIaqhPP300+zevbvg+0knncTWrVv9NN3hcKLvKIITfR+MGjWKiRMnFlk2ceJERo0a5Wv7\ngw46KOqI1liEiv7kyZNp0qRJwvWVNapakM7BUfY40XcEU+FEvzwyK5911ll88sknBROmrFixgjVr\n1jBo0KCCuPlevXrRvXt3/vWvfxXbfsWKFXTr1g2wFAnnnnsuXbt2ZcSIEQWpD8Di1720zPfeey8A\nzz77LGvWrGHIkCEMGTIEsPQIGzduBOCpp56iW7dudOvWrSAt84oVK+jatStXXHEFhx9+OCeeeGKR\n/Xh89NFH9OvXjyOOOIITTjiB9evXAzYW4NJLL6V79+706NGjII3DlClT6NWrFxkZGRx//PGAzS/w\n5JNPFtTZrVs3VqxYwYoVKzjssMO46KKL6NatG6tWrQp7fACzZs3iqKOOIiMjg759+7Jjxw6OOeaY\nIimjBw4cSHZ2dvQfyhEWJ/qOYFycvg+aNWtG3759+fTTTzn99NOZOHEiZ599NiJCnTp1eP/992nU\nqBEbN26kf//+nHbaaRHnb33hhReoV68eixYtYt68efTq1atg3UMPPUSzZs3Iy8vj+OOPZ968eVx3\n3XU89dRTfPnll6SlpRWp68cff+S1117j+++/R1Xp168fgwcPpmnTpixdupQJEybw8ssvc/bZZ/Pu\nu+9ywQUXFNl+4MCBfPfdd4gIr7zyCo8//jhjx47lgQceoHHjxsyfPx+wnPcbNmzgiiuuYObMmXTo\n0KFIHp1ILF26lDfeeIP+/ftHPL4uXbpwzjnn8Pbbb3PkkUeyfft26taty+WXX87rr7/O008/zZIl\nS9i7dy8ZGRlx/W4Ow4m+Ixhfoi8imcAzQHXgFVV9NGR9O2Ac0ALYDFygqjmB5e9jTxQ1gedU9W8l\naXB5ZVb2XDye6L/66quAuS7uuOMOZs6cSbVq1Vi9ejXr16+nVatWYeuZOXMm1113HQA9evSgR48e\nBesmTZrESy+9RG5uLmvXrmXhwoVF1ofy9ddfM2LEiIKMlyNHjuSrr77itNNOo0OHDvTs2RMompo5\nmJycHM455xzWrl3Lvn376NChA2CploPdWU2bNuWjjz7imGOOKSjjJ/1yu3btCgQ/0vGJCAceeCBH\nHnkkAI0aNQLgd7/7HQ888ABPPPEE48aN45JLLom5P0d4nOg7gonp3hGR6sDzwHAgHRglIukhxZ4E\nxqtqD+B+4JHA8rXAAFXtCfQDbhORg5LV+LLk9NNPZ/r06cyZM4fdu3fTu3dvwBKYbdiwgR9//JGs\nrCwOOOCAhNIY//LLLzz55JNMnz6defPmcfLJJydUj4eXlhkip2b+wx/+wJgxY5g/fz4vvvhiidMv\nQ9EUzMHpl+M9vnr16jF06FD+9a9/MWnSJM4///y42+YwvFBNF7LpAH8+/b7AMlVdrqr7gInA6SFl\n0oEvAp+/9Nar6j5V/S2wvLbP/aUkDRo0YMiQIVx22WVFOnC9tMI1a9bkyy+/5H//+1/Ueo455hj+\n8Y9/APDTTz8xb948wNIy169fn8aNG7N+/Xo+/fTTgm0aNmzIjh07itU1aNAgPvjgA3bv3s2uXbt4\n//33GTRokO9j2rZtG61btwbgjTfeKFg+dOhQnn/++YLvW7ZsoX///sycOZNffvkFKJp+ec6cOQDM\nmTOnYH0okY7vsMMOY+3atcyaNQuAHTt2FNygRo8ezXXXXceRRx5ZMGGLI36cpe8Ixo8ItwZWBX3P\nCSwLJhsYGfg8AmgoIs0BRKStiMwL1PGYqq4J3YGIXCkis0Vk9ob/b+/+Q+s66ziOvz+rCXeoZV0W\nh+5OV7GlXVtv00AysX/EQiXq3Ea7yNpqV7AUiisTFNm01DoWhkP8AfWfosMF/NGibitjMMsMbn91\ny9xCO9fqlEF/zKamKdp/JtOPf5wn2W1cmtv1Jqc55/uCcM95cki+X/Lke899zjnPc+bMpeYwazZs\n2MDw8PAFRX/Tpk0MDQ2xYsUKBgYGpl0QZPv27Zw/f56lS5eya9euiU8MtVqNjo4OlixZwsaNGy+Y\nlnnbtm309vZOXMgdt2rVKrZs2UJXVxfd3d1s3bqVjkuYQnH37t309fXR2dl5wfWCnTt3MjY2xvLl\ny6nVagwODtLe3s7evXtZt24dtVptYkrk9evXc/bsWZYtW8aePXtYvHjxO/6uqfJrbW1l37597Nix\ng1qtxtq1ayc+AXR2djJ//vyYc/8yjRf7eN8M0MDUypLuBHptb037XwK6bd9Td8yHgD3AQuBZYD2w\n3Pa5Scc8Dnze9umpfl9MrRzGnTp1ip6eHo4ePcpVV73z+Un0jemNjcFDD8GDD0Ldom2hYBqdWrmR\nM/2TwI11+9XUNsH2KdvrbHcA30pt5yYfAxwBGh9/CKU1MDBAd3c3/f39Uxb80JgFC+Dhh6Pgh0wj\n/00vAIskLZTUCtwFHKg/QNJ1ksZ/1v1kd/IgqSrp6rS9AFgNHGtW8KG4Nm/ezPHjx+nr68s7lBAK\nZdqib/st4B7gaeBVYL/tVyQ9IOm2dFgPcEzSn4Hrgf7UvhQ4JGkY+APwPduH302gV9oKXyF/0SdC\nuHQN3adv+yngqUltu+q2fw383zwDtg8CU99o3qBKpcLo6ChtbW1TPvQUysU2o6OjVCqVvEMJYU6Z\nE0/kVqtVTpw4wZV8Z0+YfZVKhWq1mncYIcwpc6Lot7S0TDwJGkII4d2L2yJCCKFEouiHEEKJRNEP\nIYQSmfaJ3Nkm6Qxw8QlsLu464B9NCmcuibzLJfIul0by/ojt9ul+0BVX9C+XpKFGHkUumsi7XCLv\ncmlm3jG8E0IIJRJFP4QQSqSIRX9v3gHkJPIul8i7XJqWd+HG9EMIIUytiGf6IYQQphBFP4QQSqQw\nRV9Sr6Rjkl6TdF/e8cwkSY9IGpF0pK7tWkkHJf0lvRZqcby07OagpD9JekXSvam96HlXJD0vaTjl\n/Z3UvlDSodTf96W1LgpH0jxJL0l6Mu2XJe/XJR2W9LKkodTWlL5eiKIvaR7wY+AzZIu0b5B0c75R\nzaifAb2T2u4DnrG9CHgm7RfJW8DXbN8M3AJ8Jf2Ni573m8Aa2zVgJdAr6Rbgu8APbH8MGAO+nGOM\nM+lesnU8xpUlb4BP2V5Zd39+U/p6IYo+0AW8Zvtvtv8N/Aq4PeeYZoztZ4Gzk5pvBx5N248Cd8xq\nUDPM9hu2/5i2/0VWCG6g+Hnb9vm025K+DKzh7TUsCpc3ZCvvAZ8DfpL2RQnyvoim9PWiFP0bgON1\n+ydSW5lcb/uNtP13shXMCknSTUAHcIgS5J2GOF4GRoCDwF+Bc2lVOyhuf/8h8A3gv2m/jXLkDdkb\n++8kvShpW2prSl+fE/Pph0tj25IKeS+upPcBvwG+avuf9SupFTVv2/8BVkq6BngMWJJzSDNO0q3A\niO0XJfXkHU8OVts+KekDwEFJR+u/eTl9vShn+ieBG+v2q6mtTE5L+iBAeh3JOZ6mk9RCVvB/bvu3\nqbnweY+zfQ4YBD4BXCNp/KStiP39k8Btkl4nG65dA/yI4ucNgO2T6XWE7I2+iyb19aIU/ReARenK\nfitwF3Ag55hm2wHg7rR9N/BEjrE0XRrP/Snwqu3v132r6Hm3pzN8JF0NrCW7njEI3JkOK1zetu+3\nXbV9E9n/8+9tb6LgeQNIeq+k949vA58GjtCkvl6YJ3IlfZZsDHAe8Ijt/pxDmjGSfgn0kE23ehr4\nNvA4sB/4MNnU1F+wPfli75wlaTXwHHCYt8d4v0k2rl/kvD9OdtFuHtlJ2n7bD0j6KNkZ8LXAS8AX\nbb+ZX6QzJw3vfN32rWXIO+X4WNp9D/AL2/2S2mhCXy9M0Q8hhDC9ogzvhBBCaEAU/RBCKJEo+iGE\nUCJR9EMIoUSi6IcQQolE0Q8hhBKJoh9CCCXyPw9spIcehpa7AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DtJMLnY-_MU",
        "colab_type": "code",
        "outputId": "ad6e3050-e445-4787-da01-0a65e2a444b0",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img(path, target_size=(150, 150))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  print(classes[0])\n",
        "  if classes[0]>0.5:\n",
        "    print(fn + \" is a human\")\n",
        "  else:\n",
        "    print(fn + \" is a horse\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d36bf348-bead-4bac-a521-3a647741e74c\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-d36bf348-bead-4bac-a521-3a647741e74c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving human4.jpg to human4.jpg\n",
            "[1.]\n",
            "human4.jpg is a dog\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}